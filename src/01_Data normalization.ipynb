{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_folder = r'../example/data/time-series'\n",
    "stations_csv_file = r'../example/data/Stations.csv'\n",
    "number_of_days_in_year_calcs = 250 #minimum number of days requested for yearly stats calculations\n",
    "\n",
    "max_10m_outlier_threshold = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rains_cols = ['DateTime', 'StationId', 'IR']\n",
    "df_rains = pd.DataFrame(columns=df_rains_cols)\n",
    "time_series_files = [file for file in os.listdir(time_series_folder) if '.csv' in file and '~' not in file]\n",
    "\n",
    "for rainsfile in time_series_files:\n",
    "    df = pd.read_csv(os.path.join(time_series_folder, rainsfile))\n",
    "    df.set_index('DateTime', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df[~df.index.duplicated(keep='first')] #Remove duplicates keeping first value\n",
    "    df_ex = df.resample('10T').sum()\n",
    "    df_freq_nan = df.resample('10T').asfreq()\n",
    "    df_ex.loc[df_freq_nan[df_freq_nan.IR.isnull()].index, 'IR'] = None # Change possibles GAPS in time series from 0 to NaN\n",
    "    df_ex['StationId'] = df.StationId[0]\n",
    "    df_rains = pd.concat([df_rains, df_ex.reset_index()[['DateTime', 'StationId', 'IR']]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Checks\n",
    "\n",
    "total_outliers = len(df_rains[df_rains.IR >= max_10m_outlier_threshold])\n",
    "print('There are {0} outliers in time-series.'.format(total_outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 10m time series in parquet file\n",
    "\n",
    "df_rains.to_parquet('precipitations_time_series.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 10m time series filtered in parquet file\n",
    "\n",
    "df_rains_2 = df_rains.copy()\n",
    "df_rains_2['IR'].mask(df_rains_2['IR'] >= max_10m_outlier_threshold, inplace=True)\n",
    "df_rains_2.to_parquet('precipitations_time_series_filtered.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With 10m_outlier_threshold daily rains\n",
    "\n",
    "df_daily_rains = df_rains[df_rains['IR'] < max_10m_outlier_threshold].groupby([df_rains['DateTime'].dt.date, 'StationId'])['IR'].sum().reset_index()\n",
    "df_daily_rains_na = df_rains[df_rains['IR'] < max_10m_outlier_threshold].groupby([df_rains['DateTime'].dt.date, 'StationId'])['IR'].apply(lambda x: x.sum(skipna=False)).reset_index()\n",
    "df_daily_rains.to_parquet('precipitations_daily_time_series.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_year = df_daily_rains.groupby([pd.to_datetime(df_daily_rains['DateTime']).dt.year, 'StationId']).agg({'DateTime': ['min', 'max','count'], 'IR': ['sum', lambda x: x[x > 0.2].count()]}).reset_index().droplevel(0, axis=1)\n",
    "df_stats_year.columns = ['year', 'StationID', 'Min Date', 'Max Date','Number of days with data', 'IR Sum','Raining days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.read_csv(stations_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_with_stats = pd.concat([\n",
    "                df_stations.set_index('Id'), \n",
    "                df_daily_rains.groupby('StationId').agg(['min', 'max']).droplevel(0, axis=1),\n",
    "                df_stats_year[df_stats_year['Number of days with data']>number_of_days_in_year_calcs][['StationID', 'IR Sum']].groupby('StationID').mean(),\n",
    "                df_stats_year[df_stats_year['Number of days with data']>number_of_days_in_year_calcs][['StationID', 'Raining days']].groupby('StationID').mean()\n",
    "            ], axis=1).reset_index()\n",
    "df_stations_with_stats.columns = ['StationId', 'Name', 'Latitude', 'Longitude', 'Elevation', 'Series Start', 'Series end', 'Min day IR', 'Max day IR', 'Yearly rainfall', 'Number of days with rainfall over 0.2 mm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations_with_stats.to_parquet('stations_with_stats.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
