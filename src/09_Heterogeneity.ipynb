{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lmoments3 as lm\n",
    "from lmoments3 import distr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import kappa4\n",
    "from scipy.special import gamma\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = r'../example/results/heterogeneity'\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = ['Station1','Station2','Station3','Station4','Station5','Station6','Station7'] #Selection of stations of interest within a cluster\n",
    "df_prec = pd.read_parquet('precipitations_daily_time_series.parquet')\n",
    "lmoments_list_val = list()\n",
    "for sta, df_day in df_prec.groupby('StationId'): \n",
    "    #Extracting data from db, clearing NANs and passing it into an array\n",
    "    if(sta not in stations):continue #Error values in station 8\n",
    "    df_station = df_day[df_day[\"StationId\"]==sta]\n",
    "    station = df_station[df_station['IR']>=2]['IR']\n",
    "    array = station.to_numpy()\n",
    "    x = array[~np.isnan(array)]\n",
    "    n_x = len(x)\n",
    "    sum_x = sum(x)\n",
    "    #L-moment determination\n",
    "    lamb1, lamb2, t3, t4 = lm.lmom_ratios(x, nmom=4)\n",
    "    l_CV = lamb2/lamb1\n",
    "    lmoments_list_val.append([sta, lamb1, lamb2, t3, t4, l_CV, n_x, sum_x])\n",
    "\n",
    "df_lmoments = pd.DataFrame(lmoments_list_val, columns =['station', 'lamb1', 'lamb2', 't3', 't4', 'l_CV', 'n', 'sum_x'])\n",
    "df_lmoments.to_excel(os.path.join(results_folder, 'lmoments.xlsx'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FITTING KAPPA 4 DISTRIBUTION\n",
    "\n",
    "#Determining V from observations\n",
    "N = len(df_lmoments)\n",
    "tR_den = 0\n",
    "Num = 0\n",
    "V_den = 0\n",
    "lamb1_mean_den = 0\n",
    "lamb2_mean_den = 0\n",
    "l_CV_mean_den = 0\n",
    "tau3_mean_den = 0\n",
    "tau4_mean_den = 0\n",
    "\n",
    "for i in range(0, N):\n",
    "    tR_den = tR_den + df_lmoments.at[i, 'n']*df_lmoments.at[i, 'l_CV']\n",
    "    lamb1_mean_den = lamb1_mean_den + df_lmoments.at[i, 'n']*df_lmoments.at[i, 'lamb1']\n",
    "    lamb2_mean_den = lamb2_mean_den + df_lmoments.at[i, 'n']*df_lmoments.at[i, 'lamb2']\n",
    "    l_CV_mean_den = l_CV_mean_den + df_lmoments.at[i, 'n']*df_lmoments.at[i, 'l_CV']\n",
    "    tau3_mean_den = tau3_mean_den + df_lmoments.at[i, 'n']*df_lmoments.at[i, 't3']\n",
    "    tau4_mean_den = tau4_mean_den + df_lmoments.at[i, 'n']*df_lmoments.at[i, 't4']\n",
    "    Num = Num + df_lmoments.at[i, 'n']\n",
    "        \n",
    "Mean_tR = tR_den/Num\n",
    "t3_reg = tau3_mean_den/Num\n",
    "t4_reg = tau4_mean_den/Num\n",
    "lamb1_reg = lamb1_mean_den/Num\n",
    "lamb2_reg = lamb2_mean_den/Num\n",
    "l_CV_reg = l_CV_mean_den/Num\n",
    "    \n",
    "#print('Weighted means: t =', l_CV_reg, ', t_3 =',t3_reg, ', t_4 =', t4_reg)\n",
    "\n",
    "for i in range(0,N):\n",
    "    V_den = V_den + df_lmoments.at[i, 'n']*(df_lmoments.at[i, 'l_CV']-Mean_tR)**2\n",
    "\n",
    "V = (V_den/Num)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Kappa4\n",
    "#g_r functions\n",
    "def calculate_g_r(h, k, r):\n",
    "    if h > 0:\n",
    "        return (r * gamma(1 + k) * gamma(r / h)) / (h**(1 + k) * gamma(1 + k + (r / h)))\n",
    "    else:\n",
    "        return (r * gamma(1 + k) * gamma(-k - (r / h))) / ((-h)**(1 + k) * gamma(1 - (r / h)))\n",
    "\n",
    "\n",
    "def objective_function(params):\n",
    "    h, k = params \n",
    "\n",
    "    #g_r functions calculations\n",
    "    g1 = calculate_g_r(h, k, 1)\n",
    "    g2 = calculate_g_r(h, k, 2)\n",
    "    g3 = calculate_g_r(h, k, 3)\n",
    "    g4 = calculate_g_r(h, k, 4)\n",
    "\n",
    "    #t3' y t4' calculations\n",
    "    t3_prime = (-g1 + 3 * g2 - 2 * g3) / (g1 - g2)\n",
    "    t4_prime = (-g1 + 6 * g2 - 10 * g3 + 5 * g4) / (g1 - g2)\n",
    "\n",
    "    #error calculation\n",
    "    diff_t3 = (np.abs(t3_prime) - np.abs(t3_reg))**2\n",
    "    diff_t4 = (np.abs(t4_prime) - np.abs(t4_reg))**2\n",
    "    error = (np.abs(diff_t3) + np.abs(diff_t4))**0.5\n",
    "\n",
    "    return error\n",
    "\n",
    "\n",
    "x0 = np.array([0.1, 0])\n",
    "    \n",
    "res = minimize(objective_function, x0, method='nelder-mead', options={'xatol': 1e-8, 'disp': False})\n",
    "x_min = res.x\n",
    "\n",
    "#k and h saving values\n",
    "best_h = x_min[0]\n",
    "best_k = x_min[1]\n",
    "    \n",
    "#alpha and beta calculations\n",
    "    \n",
    "alpha = (l_CV_reg * best_k) / (calculate_g_r(best_h, best_k, 1) - calculate_g_r(best_h, best_k, 2))\n",
    "locat = 1-(1-calculate_g_r(best_h, best_k, 1)) * alpha / best_k\n",
    "    \n",
    "print('Parameters of regional kappa distribution: loc =', locat, ', alpha =', alpha, ', k =', best_k, ', h =', best_h)\n",
    "\n",
    "J = (best_h, best_k, locat, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulating Monte Carlo series\n",
    "\n",
    "N_sites = N\n",
    "N_sim = 1000\n",
    "lmoments_sim_val = list()\n",
    "V_sim = list()\n",
    "for d1 in range(N_sim):\n",
    "    TR_den = 0\n",
    "    num = 0\n",
    "    L_cv_val = list()\n",
    "    for d2 in range(N_sites):\n",
    "        random_samples = kappa4.rvs(J[0], J[1], loc=J[2], scale=J[3], size=df_lmoments.at[d2, 'n'])\n",
    "        #L-moment determination\n",
    "        l1, l2, tau3, tau4 = lm.lmom_ratios(random_samples, nmom=4)\n",
    "        L_cv = l2/l1\n",
    "        n_prima = len(random_samples)\n",
    "        lmoments_sim_val.append([d1, d2, l1, l2, tau3, tau4, L_cv, n_prima])\n",
    "        L_cv_val.append([d2, L_cv, n_prima])\n",
    "        TR_den = TR_den + df_lmoments.at[d2, 'n']*L_cv\n",
    "        num = num + df_lmoments.at[d2, 'n']\n",
    "        df_L_cv = pd.DataFrame(L_cv_val, columns =['Sites','L_cv', 'n_prima'])\n",
    "        \n",
    "    Mean_TR = TR_den/num\n",
    "    V1_den = 0\n",
    "    for d3 in range(N_sites):\n",
    "        V1_den = V1_den + df_L_cv.at[d3, 'n_prima']*(df_L_cv.at[d3, 'L_cv']- Mean_TR)**2\n",
    "        \n",
    "    V1 = (V1_den/(num))**0.5\n",
    "    V_sim.append([d1, V1])\n",
    "        \n",
    "#df_lmoments_sim_val = pd.DataFrame(lmoments_sim_val, columns =['Sim', 'Sites', 'l1', 'l2', 'tau3', 'tau4', 'L_cv', 'n_prima'])\n",
    "#df_lmoments_sim_val.to_excel(os.path.join(results_folder, 'lmoments_sim.xlsx'), index=False)\n",
    "df_V1 = pd.DataFrame(V_sim, columns =['Sim', 'V'])\n",
    "#df_V1.to_excel(os.path.join(results_folder, 'V_sim.xlsx'), index=False)\n",
    "\n",
    "#Calculating the Heterogeneity\n",
    "\n",
    "df_V = df_V1['V']\n",
    "vals = df_V.to_numpy()\n",
    "V_sim_mean = np.mean(vals)\n",
    "V_sim_std = np.std(vals)\n",
    "\n",
    "H = (V-V_sim_mean)/V_sim_std\n",
    "\n",
    "print(H)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
